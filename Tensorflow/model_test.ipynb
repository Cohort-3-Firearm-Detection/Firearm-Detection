{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465cbf3c",
   "metadata": {},
   "source": [
    "# 0. Setup Paths and Dependencies \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "084a7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = 'workspace'\n",
    "SCRIPTS_PATH = 'scripts'\n",
    "APIMODEL_PATH = 'models'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n",
    "CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mobnet/'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a54efe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36315be5",
   "metadata": {},
   "source": [
    "# 1. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aed5b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model you want to use for detection \n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c9615bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'workspace/models/my_ssd_mobnet/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHECKPOINT_PATH = MODEL_PATH+'/{}/'.format(CUSTOM_MODEL_NAME)\n",
    "CHECKPOINT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80a0cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-13')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21bbc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ccc4fc",
   "metadata": {},
   "source": [
    "### Bash Command for Retrieving Model Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bae1361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/my_ssd_mobnet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this output in a bash terminal in the root directory to get the performance metrics \n",
    "print(\"\"\"python {}/research/object_detection/model_main_tf2.py --model_dir={}/{} --pipeline_config_path={}/{}/pipeline.config --checkpoint_dir={}/{}\n",
    "\"\"\".format(APIMODEL_PATH, MODEL_PATH, CUSTOM_MODEL_NAME, MODEL_PATH, CUSTOM_MODEL_NAME, MODEL_PATH, CUSTOM_MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1ab23",
   "metadata": {},
   "source": [
    "# 2. Detect on Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1604e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps you will train \n",
    "STEPS = '10000'\n",
    "# Image you want to test \n",
    "IMAGE = 'guntest2'\n",
    "# Path for the image you want to test \n",
    "TEST_IMAGE_PATH = '{}/{}.png'.format(IMAGE_PATH, IMAGE)\n",
    "# Path and \n",
    "OUTPUT_PATH = '{}/{}_{}_steps_{}_result.png'.format(IMAGE_PATH, IMAGE, STEPS, CUSTOM_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f3306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking how the detected image is displayed \n",
    "# %matplotlib inline\n",
    "plt.switch_backend('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d920e9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7648075\n",
      "0.21023057\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(TEST_IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype = tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "             for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "    image_np_with_detections,\n",
    "    detections['detection_boxes'],\n",
    "    detections['detection_classes']+label_id_offset,\n",
    "    detections['detection_scores'], \n",
    "    category_index,\n",
    "    use_normalized_coordinates=True,\n",
    "    max_boxes_to_draw=2,\n",
    "    min_score_thresh=.6,\n",
    "    agnostic_mode=False)\n",
    "\n",
    "print(detections['detection_scores'][0])\n",
    "print(detections['detection_scores'][1])\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.savefig(OUTPUT_PATH)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e331c",
   "metadata": {},
   "source": [
    "# 3. Detect in Real-Time and Videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4158c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for video capture\n",
    "cap = cv2.VideoCapture(IMAGE_PATH + '/KeanuTestShort.mp4')\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('your_video.avi', fourcc, 20.0, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8caf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for live detection with webcam \n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaf9b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=3,\n",
    "                min_score_thresh=.6,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    # For video files and saves them \n",
    "    if ret == True:\n",
    "        # Saves for video\n",
    "        out.write(image_np_with_detections)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('object detection', cv2.resize(image_np_with_detections, (1280, 720))) #(800, 600)))\n",
    "\n",
    "        # Close window when \"Q\" button pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            break\n",
    "\n",
    "    # For live feed \n",
    "#     cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (1280, 720))) #(800, 600)))\n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         cap.release()\n",
    "#         break\n",
    "\n",
    "        \n",
    "cap.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6815e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stops detection \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199d0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
